{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[1;31mInit signature:\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;31mDocstring:\u001b[0m     \nLayer that averages a list of inputs element-wise.\n\nIt takes as input a list of tensors, all of the same shape, and returns\na single tensor (also of the same shape).\n\nExample:\n\n>>> x1 = np.ones((2, 2))\n>>> x2 = np.zeros((2, 2))\n>>> y = tf.keras.layers.Average()([x1, x2])\n>>> y.numpy().tolist()\n[[0.5, 0.5], [0.5, 0.5]]\n\nUsage in a functional model:\n\n>>> input1 = tf.keras.layers.Input(shape=(16,))\n>>> x1 = tf.keras.layers.Dense(8, activation='relu')(input1)\n>>> input2 = tf.keras.layers.Input(shape=(32,))\n>>> x2 = tf.keras.layers.Dense(8, activation='relu')(input2)\n>>> avg = tf.keras.layers.Average()([x1, x2])\n>>> out = tf.keras.layers.Dense(4)(avg)\n>>> model = tf.keras.models.Model(inputs=[input1, input2], outputs=out)\n\nRaises:\n  ValueError: If there is a shape mismatch between the inputs and the shapes\n    cannot be broadcasted to match.\n\u001b[1;31mInit docstring:\u001b[0m\nIntializes a Merge layer.\n\nArguments:\n  **kwargs: standard layer keyword arguments.\n\u001b[1;31mFile:\u001b[0m           c:\\users\\administrator\\.conda\\envs\\tf2gpu\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\merge.py\n\u001b[1;31mType:\u001b[0m           type\n\u001b[1;31mSubclasses:\u001b[0m     \n"
    }
   ],
   "source": [
    "layers.Average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['AbstractRNNCell',\n 'Activation',\n 'ActivityRegularization',\n 'Add',\n 'AdditiveAttention',\n 'AlphaDropout',\n 'Attention',\n 'Average',\n 'AveragePooling1D',\n 'AveragePooling2D',\n 'AveragePooling3D',\n 'AvgPool1D',\n 'AvgPool2D',\n 'AvgPool3D',\n 'BatchNormalization',\n 'Bidirectional',\n 'Concatenate',\n 'Conv1D',\n 'Conv2D',\n 'Conv2DTranspose',\n 'Conv3D',\n 'Conv3DTranspose',\n 'ConvLSTM2D',\n 'Convolution1D',\n 'Convolution2D',\n 'Convolution2DTranspose',\n 'Convolution3D',\n 'Convolution3DTranspose',\n 'Cropping1D',\n 'Cropping2D',\n 'Cropping3D',\n 'Dense',\n 'DenseFeatures',\n 'DepthwiseConv2D',\n 'Dot',\n 'Dropout',\n 'ELU',\n 'Embedding',\n 'Flatten',\n 'GRU',\n 'GRUCell',\n 'GaussianDropout',\n 'GaussianNoise',\n 'GlobalAveragePooling1D',\n 'GlobalAveragePooling2D',\n 'GlobalAveragePooling3D',\n 'GlobalAvgPool1D',\n 'GlobalAvgPool2D',\n 'GlobalAvgPool3D',\n 'GlobalMaxPool1D',\n 'GlobalMaxPool2D',\n 'GlobalMaxPool3D',\n 'GlobalMaxPooling1D',\n 'GlobalMaxPooling2D',\n 'GlobalMaxPooling3D',\n 'Input',\n 'InputLayer',\n 'InputSpec',\n 'LSTM',\n 'LSTMCell',\n 'Lambda',\n 'Layer',\n 'LayerNormalization',\n 'LeakyReLU',\n 'LocallyConnected1D',\n 'LocallyConnected2D',\n 'Masking',\n 'MaxPool1D',\n 'MaxPool2D',\n 'MaxPool3D',\n 'MaxPooling1D',\n 'MaxPooling2D',\n 'MaxPooling3D',\n 'Maximum',\n 'Minimum',\n 'Multiply',\n 'PReLU',\n 'Permute',\n 'RNN',\n 'ReLU',\n 'RepeatVector',\n 'Reshape',\n 'SeparableConv1D',\n 'SeparableConv2D',\n 'SeparableConvolution1D',\n 'SeparableConvolution2D',\n 'SimpleRNN',\n 'SimpleRNNCell',\n 'Softmax',\n 'SpatialDropout1D',\n 'SpatialDropout2D',\n 'SpatialDropout3D',\n 'StackedRNNCells',\n 'Subtract',\n 'ThresholdedReLU',\n 'TimeDistributed',\n 'UpSampling1D',\n 'UpSampling2D',\n 'UpSampling3D',\n 'Wrapper',\n 'ZeroPadding1D',\n 'ZeroPadding2D',\n 'ZeroPadding3D',\n '__builtins__',\n '__cached__',\n '__doc__',\n '__file__',\n '__loader__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '_sys',\n 'add',\n 'average',\n 'concatenate',\n 'deserialize',\n 'dot',\n 'experimental',\n 'maximum',\n 'minimum',\n 'multiply',\n 'serialize',\n 'subtract']"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dir(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as ktf\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.models import load_model,Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from location.network import *\n",
    "from location.losses import *\n",
    "from recognition.network import *\n",
    "\n",
    "from util import *\n",
    "import cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path=\"demo/046.jpg\"\n",
    "img = image.load_img(img_path)\n",
    "d_wight, d_height = resize_image(img, cfg.image_size)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.img_to_array(img)\n",
    "image.random_brightness(img,brightness_range=(0.8,0.8))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#img = img.resize((d_wight, d_height), Image.NEAREST).convert('RGB')\n",
    "img = image.img_to_array(img)\n",
    "#img = img/255*2-1\n",
    "preprocess_input(img,mode='tf')\n",
    "#plt.imshow(image.array_to_img(img))\n",
    "#image.random_brightness(img,brightness_range=(0.5,0.9))\n",
    "plt.imshow(img)\n",
    "plt.imshow(image.array_to_img(img))\n",
    "#image.img_to_array(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.array_to_img(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_model = tf.keras.models.load_model(r\"location\\saved_model\\location_pb\",compile=False)\n",
    "location_model.compile(loss=quad_loss,optimizer='Nadam')\n",
    "tf.keras.models.save_model(location_model ,r\"location\\saved_model\\location_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_model = Location().location_network()\n",
    "location_model.load_weights(cfg.location_weights)\n",
    "location_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, recognition_model = CRNN(cfg.width, cfg.height, cfg.label_len, cfg.characters).network()\n",
    "recognition_model.load_weights(cfg.recognition_weights)\n",
    "recognition_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单图测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img_path = 'demo/046.jpg'\n",
    "img = image.load_img(img_path,target_size=(512,512))\n",
    "plt.figure(figsize=(15,20))\n",
    "plt.subplot(1,3,1)\n",
    "plt.xlabel('input')\n",
    "plt.imshow(img)\n",
    "ims_re = location(location_model, img_path,cfg.pixel_threshold)\n",
    "if(len(ims_re)>0):\n",
    "    #print(len(ims_re))\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(ims_re[0])\n",
    "    re_text = recognition(recognition_model, ims_re[0])\n",
    "    result = img_path + \" \" + re_text + \"\\n\"\n",
    "    print('recognize result: '+ re_text)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检测计时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "img_path = 'demo/046.jpg'\n",
    "img = image.load_img(img_path,target_size=(512,512))\n",
    "plt.figure(figsize=(15,20))\n",
    "plt.subplot(1,3,1)\n",
    "plt.xlabel('input')\n",
    "plt.imshow(img)\n",
    "ims_re = location(location_model, img_path,cfg.pixel_threshold)\n",
    "if(len(ims_re)>0):\n",
    "    #print(len(ims_re))\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(ims_re[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 识别计时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "re_text = recognition(recognition_model, ims_re[0])\n",
    "result = img_path + \" \" + re_text + \"\\n\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文件夹图片检测识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "imgs = os.listdir('demo')\n",
    "for img in imgs:\n",
    "    img_path = os.path.join('demo', img)\n",
    "    ims_re = location(location_model, img_path, cfg.pixel_threshold)\n",
    "    if len(ims_re) > 0:\n",
    "        for i in range(len(ims_re)):\n",
    "            re_text = recognition(recognition_model, ims_re[0])\n",
    "            result = img + \" \" + re_text + \"\\n\"\n",
    "            print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全数据集测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 'labels.txt'\n",
    "def acc_calculate(labels='labels.txt',results='result.txt'):\n",
    "    with open(labels) as label:\n",
    "        linexs = label.readlines()\n",
    "    with open(results) as result:\n",
    "        lineys = result.readlines()\n",
    "    cnt = 0\n",
    "    for linex in linexs:\n",
    "        linex = linex.split()\n",
    "        for liney in lineys:\n",
    "            liney = liney.split()\n",
    "            if linex[0] == liney[0] and len(liney) > 1:\n",
    "                if linex[1] == liney[1]:\n",
    "                    cnt = cnt + 1\n",
    "    acc=cnt/len(lineys)\n",
    "    return  acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc=acc_calculate(labels,\"recognition/result.txt\")\n",
    "print('{0:.3%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 检测测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results='east_train_result.txt'\n",
    "with open(results, 'w+') as txt:\n",
    "    with open(r'Z:\\Code\\Python\\datas\\Augment_meter\\east_train.txt') as val:\n",
    "        lines =val.readlines()\n",
    "        for line in lines:\n",
    "            img_name=line.split(',')[0]\n",
    "            img_path=os.path.join('Z:\\Code\\Python\\datas\\Augment_meter\\imgs_east_512',img_name)\n",
    "            ims_re = location(location_model, img_path, cfg.pixel_threshold)\n",
    "            if len(ims_re) > 0:\n",
    "                re_text = recognition(recognition_model, ims_re[0])\n",
    "                result =  img_name+ \" \" + re_text + \"\\n\"\n",
    "                #print(result)\n",
    "                txt.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=acc_calculate(labels,results)\n",
    "print('{0:.3%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results='east_val_result.txt'\n",
    "with open(results, 'w+') as txt:\n",
    "    with open(r'Z:\\Code\\Python\\datas\\Augment_meter\\east_val.txt') as val:\n",
    "        lines =val.readlines()\n",
    "        for line in lines:\n",
    "            img_name=line.split(',')[0]\n",
    "            img_path=os.path.join('Z:\\Code\\Python\\datas\\Augment_meter\\imgs_east_512',img_name)\n",
    "            ims_re = location(location_model, img_path, cfg.pixel_threshold)\n",
    "            if len(ims_re) > 0:\n",
    "                for i in range(len(ims_re)):\n",
    "                    re_text = recognition(recognition_model, ims_re[i])\n",
    "                    result =  img_name+ \" \" + re_text + \"\\n\"\n",
    "                    print(result)\n",
    "                    txt.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=acc_calculate(labels,results)\n",
    "print('{0:.3%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 识别测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results='crnn_train_result.txt'\n",
    "with open(results, 'w+') as txt:\n",
    "    with open(r'Z:\\Code\\Python\\datas\\Augment_meter\\crnn_train.txt') as val:\n",
    "        lines =val.readlines()\n",
    "        for line in lines:\n",
    "            img_name=line.split(' ')[0]\n",
    "            img_path=os.path.join('Z:\\Code\\Python\\datas\\Augment_meter\\imgs_east_512',img_name)\n",
    "            ims_re = location(location_model, img_path, cfg.pixel_threshold)\n",
    "            if len(ims_re) > 0:\n",
    "                re_text = recognition(recognition_model, ims_re[0])\n",
    "                result =  img_name+ \" \" + re_text + \"\\n\"\n",
    "                print(result)\n",
    "                txt.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=acc_calculate(labels,results)\n",
    "print('{0:.3%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results='crnn_val_result.txt'\n",
    "with open(results, 'w+') as txt:\n",
    "    with open(r'Z:\\Code\\Python\\datas\\Augment_meter\\crnn_val.txt') as val:\n",
    "        lines =val.readlines()\n",
    "        for line in lines:\n",
    "            img_name=line.split(' ')[0]\n",
    "            img_path=os.path.join('Z:\\Code\\Python\\datas\\Augment_meter\\imgs_east_512',img_name)\n",
    "            ims_re = location(location_model, img_path, cfg.pixel_threshold)\n",
    "            if len(ims_re) > 0:\n",
    "                for i in range(len(ims_re)):\n",
    "                    re_text = recognition(recognition_model, ims_re[i])\n",
    "                    result =  img_name+ \" \" + re_text + \"\\n\"\n",
    "                    print(result)\n",
    "                    txt.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=acc_calculate(labels,results)\n",
    "print('{0:.3%}'.format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('tf2gpu': conda)",
   "language": "python",
   "name": "python37764bittf2gpucondad09329ed051643c0b429750345056197"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}